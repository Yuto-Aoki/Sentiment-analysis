{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import CaboCha\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(tree, chunk):\n",
    "    surface = ''\n",
    "    for i in range(chunk.token_pos, chunk.token_pos + chunk.token_size):\n",
    "        token = tree.token(i)\n",
    "        features = token.feature.split(',')\n",
    "        if features[0] == '名詞':\n",
    "            surface += token.surface\n",
    "        elif features[0] == '形容詞':\n",
    "            surface += features[6]\n",
    "            break\n",
    "        elif features[0] == '動詞':\n",
    "            surface += features[6]\n",
    "            break\n",
    "    return surface\n",
    "\n",
    "def get_2_words(line):\n",
    "    cp = CaboCha.Parser('-f1')\n",
    "    tree = cp.parse(line)\n",
    "    chunk_dic = {}\n",
    "    chunk_id = 0\n",
    "    for i in range(0, tree.size()):\n",
    "        token = tree.token(i)\n",
    "        if token.chunk:\n",
    "            chunk_dic[chunk_id] = token.chunk\n",
    "            chunk_id += 1\n",
    "\n",
    "    tuples = []\n",
    "    for chunk_id, chunk in chunk_dic.items():\n",
    "        if chunk.link > 0:\n",
    "            from_surface =  get_word(tree, chunk)\n",
    "            to_chunk = chunk_dic[chunk.link]\n",
    "            to_surface = get_word(tree, to_chunk)\n",
    "            tuples.append((from_surface, to_surface))\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#口コミを１文ずつに切り分けし、その文章内を係り受け解析し（単語A,単語B）にkawaii_wordがあればリストに加える\n",
    "def taples_kawaii(txt):\n",
    "    kawaii_word = ['可愛い','かわいい','カワイイ','美人','綺麗','きれい','美しい','美女']\n",
    "    sen = regex.split(r'(?<=[。？])(?!$)', txt, flags=regex.VERSION1)\n",
    "    add_list=[]\n",
    "    for i in sen:\n",
    "        tuples = get_2_words(i)\n",
    "        for j in tuples:\n",
    "            for k in kawaii_word:\n",
    "                if k in j:\n",
    "                    add_list.append(j)\n",
    "    return add_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#形態素解析するための関数を定義\n",
    "tagger = MeCab.Tagger('-Owakati')#タグはMeCab.Tagger（neologd辞書）を使用したい\n",
    "tagger.parse('')\n",
    "def tokenize_ja(text, lower):\n",
    "    node = tagger.parseToNode(str(text))\n",
    "    while node:\n",
    "        if lower and node.feature.split(',')[0] in [\"名詞\",\"形容詞\"]:#分かち書きで取得する品詞を指定\n",
    "            yield node.surface.lower()\n",
    "        node = node.next\n",
    "def tokenize(content, token_min_len, token_max_len, lower):\n",
    "    return [\n",
    "        str(token) for token in tokenize_ja(content, lower)\n",
    "        if token_min_len <= len(token) <= token_max_len and not token.startswith('_')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kawaii_wordが含まれた（単語A,単語B）をさらに形態素解析し、tennin_wordが含まれていたらフラグ立てをする\n",
    "def tennin_hantei(i):\n",
    "\n",
    "    txt = tokenize(i, 2, 10000, True)\n",
    "\n",
    "    vector_list =[]\n",
    "\n",
    "    a = 0\n",
    "\n",
    "    tennin_word = ['店員','スタッフ','女将','女性','店主','助手','奥さん','奥様','店長']\n",
    "    for k in txt:\n",
    "        if k in tennin_word:\n",
    "            a+=1\n",
    "        else:\n",
    "            a+=0        \n",
    "    if a >=1:\n",
    "        kawaii_flg = 1\n",
    "    else:\n",
    "        kawaii_flg = 0\n",
    "\n",
    "    return kawaii_flg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>score</th>\n",
       "      <th>lunch_review</th>\n",
       "      <th>dinner_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>日本橋蛎殻町 すぎた</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n          2019年2月　再訪☆週末の夜、2回転目のすぎたさん。相変わらずのつ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>日本橋蛎殻町 すぎた</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n          【つまみ】相変わらず酒の進む佳肴の数々だ。◉皮剥 肝醤油◉長崎壱岐産...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>日本橋蛎殻町 すぎた</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n          この日は久々にかみさんと。「子供の面倒は？」という質問には黙秘権を使...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>日本橋蛎殻町 すぎた</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n          今回訪問したのは日本最高の評価を受けるすぎた。予約困難店で、15日の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>日本橋蛎殻町 すぎた</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n          蛎殻町である。水天宮を通り抜け、到着。同行者が車のため、駐車場は近く...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id  store_name score lunch_review  \\\n",
       "0        44  日本橋蛎殻町 すぎた   4.5          NaN   \n",
       "1        44  日本橋蛎殻町 すぎた   4.5          NaN   \n",
       "2        44  日本橋蛎殻町 すぎた   5.0          NaN   \n",
       "3        44  日本橋蛎殻町 すぎた   5.0          NaN   \n",
       "4        44  日本橋蛎殻町 すぎた   4.6          NaN   \n",
       "\n",
       "                                       dinner_review  \n",
       "0  \\n          2019年2月　再訪☆週末の夜、2回転目のすぎたさん。相変わらずのつ...  \n",
       "1  \\n          【つまみ】相変わらず酒の進む佳肴の数々だ。◉皮剥 肝醤油◉長崎壱岐産...  \n",
       "2  \\n          この日は久々にかみさんと。「子供の面倒は？」という質問には黙秘権を使...  \n",
       "3  \\n          今回訪問したのは日本最高の評価を受けるすぎた。予約困難店で、15日の...  \n",
       "4  \\n          蛎殻町である。水天宮を通り抜け、到着。同行者が車のため、駐車場は近く...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed_all_results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 15/17212 [00:10<2:34:03,  1.86it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f19e2bdb2198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnew_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnew_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtaples_kawaii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mkawaii_flg_list2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mkawaii_flg_list3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-cb0f0a6d182e>\u001b[0m in \u001b[0;36mtaples_kawaii\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtaples_kawaii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mkawaii_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'可愛い'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'かわいい'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'カワイイ'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'美人'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'綺麗'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'きれい'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'美しい'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'美女'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'(?<=[。？])(?!$)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVERSION1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0madd_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuuto\\env_scraping\\lib\\site-packages\\regex\\regex.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(pattern, string, maxsplit, flags, concurrent, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[0moccur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0melement\u001b[0m \u001b[0mof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     the list.\"\"\"\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m def splititer(pattern, string, maxsplit=0, flags=0, concurrent=None, timeout=None,\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 400)\n",
    "list_sentence = df['dinner_review'].tolist()\n",
    "\n",
    "new_list=[]\n",
    "for txt in tqdm(list_sentence):\n",
    "    new_list.append(taples_kawaii(txt))\n",
    "kawaii_flg_list2=[]\n",
    "kawaii_flg_list3=[]\n",
    "for k in new_list:\n",
    "    kawaii_flg_list=[]\n",
    "    if len(k)==0:\n",
    "        kawaii_flg_list.append(0)\n",
    "    else: \n",
    "        for i in k:\n",
    "                kawaii_flg_list.append(tennin_hantei(i))\n",
    "                if tennin_hantei(i)==1:\n",
    "                    kawaii_flg_list3.append(sum(kawaii_flg_list))\n",
    "\n",
    "df['kawaii_flg']=kawaii_flg_list3\n",
    "df_ramen = df.groupby(['store_name','score'])['dinner_review'].apply(list).apply(' '.join).reset_index().sort_values('score', ascending=False)\n",
    "df_ramen2 = df.groupby(['store_name','score'])['kawaii_flg'].sum().reset_index().sort_values('kawaii_flg', ascending=False)\n",
    "df_ramen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
